{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e427fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f348a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "fnam = \"/home/jbassham/jack/thesis-rough/data/sh/outputs/cnn/weighted/CNNPreds_sh_1992_2020.npz\"\n",
    "data = np.load(fnam, allow_pickle = True)\n",
    "\n",
    "y_pred = data['y_pred']\n",
    "y_true = data['y_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35796343",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred=  y_pred[:,0,:,:]\n",
    "u_true = y_true[:,0,:,:]\n",
    "\n",
    "v_pred = y_pred[:,1,:,:]\n",
    "v_true = y_pred[:,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e16b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latitude longitude grid for plotting\n",
    "fnam = \"/home/jbassham/jack/thesis-rough/data/sh/inputs/lat_lon_sh_1992_2020.npz\"\n",
    "data = np.load(fnam, allow_pickle = True)\n",
    "\n",
    "lat = data['lat']\n",
    "lon = data['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072652db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN data split indices and land mask\n",
    "fnam = \"/home/jbassham/jack/thesis-rough/data/sh/cnn-inputs/indices_land_sh_1992_2020.npz\"\n",
    "data = np.load(fnam, allow_pickle = True)\n",
    "\n",
    "train_idx = data['train_idx']\n",
    "val_idx = data['val_idx']\n",
    "test_idx = data['test_idx']\n",
    "land_mask = data['land_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45adebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncertainty, ice velocities\n",
    "fnam = \"/home/jbassham/jack/thesis-rough/data/sh/inputs/inputs_normalized_sh_1992_2020.npz\"\n",
    "data = np.load(fnam, allow_pickle=True)\n",
    "rt = data['rtn']\n",
    "uit = data['uitn']\n",
    "vit = data['vitn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b12bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop uncertainty, ice velocities to test indices\n",
    "r_test = rt[test_idx,:,:]\n",
    "ui_test = uit[test_idx,:,:] \n",
    "vi_test = vit[test_idx,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(pred, true):\n",
    "\n",
    "    \"\"\"\n",
    "    Pearson Correlation\n",
    "    \"\"\"\n",
    "\n",
    "    predbar = np.nanmean(pred, axis = 0) # mean predicted\n",
    "    truebar = np.nanmean(true, axis = 0) # mean true\n",
    "\n",
    "    covariance = np.nansum((pred - predbar) * (true - truebar), axis = 0) # covariance between predicted and true\n",
    "    \n",
    "    stdpred = np.sqrt(np.nansum((pred - predbar)**2), axis = 0) # standard deviation predited\n",
    "    stdtrue = np.sqrt(np.nansum((true - truebar)**2), axis = 0) # standard deviation true\n",
    "\n",
    "    correlation = covariance / (stdpred * stdtrue)\n",
    "\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_correlation(pred, true, r, epsilon = 1e-4):\n",
    "\n",
    "    \"\"\"\n",
    "    Weighted Pearson Correlation referenced from:\n",
    "    https://www.air.org/sites/default/files/2021-06/Weighted-and-Unweighted-Correlation-Methods-Large-Scale-Educational-Assessment-April-2018.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    w = 1 / (r + epsilon)\n",
    "\n",
    "    def weighted_mean(x, w):\n",
    "        return np.nansum(w * w, axis = 0) / np.nansum(w, axis = 0)\n",
    "\n",
    "    predbar = weighted_mean(pred, axis = 0) # weighted mean predicted\n",
    "    truebar = weighted_mean(true, axis = 0) # weighted mean true\n",
    "\n",
    "    weighted_cov = np.nansum( w * (pred - predbar) * (true - truebar), axis = 0) # weighted covariance between predicted and true\n",
    "    \n",
    "    weighted_stdpred = np.sqrt(np.nansum(w * (pred - predbar)**2), axis = 0) # weighted standard deviation predited\n",
    "    weighted_stdtrue = np.sqrt(np.nansum(w * (true - truebar)**2), axis = 0) # weighted standard deviation true\n",
    "\n",
    "    correlation = weighted_cov / (weighted_stdpred * weighted_stdtrue)\n",
    "\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill(pred, true, epsilon = 1e-4):\n",
    "    # NOTE excluding epsilon = 1e-4 from denominator for now\n",
    "\n",
    "    mse = np.nanmean((true - pred)**2, axis = 0) # mean square error\n",
    "    # NOTE above is not equivalent to np.nanvar(true-pred), which excludes bias term\n",
    "    # MSE = E[(y-x)^2]\n",
    "    # = (E[y-x])^2 + Var(y-x)\n",
    "    # = bias^2 + Var(y-x)\n",
    "    # Can prove the above\n",
    "\n",
    "    truebar = np.nanmean(true, axis = 0) # mean true\n",
    "\n",
    "    vartrue = np.nanmean((true - truebar)**2, axis = 0) # variance in true\n",
    "    # NOTE above is equivalent to np.nanvar()\n",
    "\n",
    "    skill = 1 - mse / vartrue\n",
    "\n",
    "    return skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c9f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_skill(pred, true, r, epsilon = 1e-4):\n",
    "    # NOTE excluding epsilon = 1e-4 from denominator for now\n",
    "    # NOTE including epsilon = 1e-4 in the weights in case of uncertainty r ~ 0\n",
    "\n",
    "    w = 1 / (r + epsilon)\n",
    "\n",
    "    mse = np.nanmean(( w * (true - pred))**2, axis = 0) # mean square error\n",
    "    # NOTE above is not equivalent to np.nanvar(true-pred), which excludes bias term\n",
    "\n",
    "    truebar = np.nanmean(true, axis = 0) # mean true\n",
    "\n",
    "    vartrue = np.nanmean(( w * (true - truebar))**2, axis = 0) # variance in true\n",
    "    # NOTE above is equivalent to np.nanvar()\n",
    "\n",
    "    weighted_skill = 1 - mse / vartrue\n",
    "\n",
    "    return weighted_skill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seaice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
